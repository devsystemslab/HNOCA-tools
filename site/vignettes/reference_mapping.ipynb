{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference mapping with HNOCA-tools\n",
    "In this tutorial we'll explore how to perform reference mapping using the HNOCA toolbox. Analogous to our analysis in the HNOCA manuscript, we map an organoid morphogen screen dataset ([Amin at al.](https://www.biorxiv.org/content/10.1101/2023.05.31.541819v1.full.pdf)) to a reference atlas of the developing human brain ([Braun at al.](https://www.science.org/doi/10.1126/science.adf1226)). We already trained a [scANVI](https://docs.scvi-tools.org/en/stable/user_guide/models/scanvi.html) model for this. Based on this model HNOCA-tools provides functions to map the organoid data to the reference atlas and make quantitative comparisons.\n",
    "\n",
    "To get started, we first load all necessary pacakges and load the data & model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scvi \n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hnoca.map as hmap\n",
    "\n",
    "os.chdir(\"/home/fleckj/scratch/hnoca/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m File scarches_BraunLinnarsson/model.pt/model.pt already downloaded                                        \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ScanVI Model with the following params: \n",
       "unlabeled_category: Unknown, n_hidden: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, n_latent: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>, n_layers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, dropout_rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>, dispersion: gene, \n",
       "gene_likelihood: zinb\n",
       "Training status: Trained\n",
       "Model's adata is minified?: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ScanVI Model with the following params: \n",
       "unlabeled_category: Unknown, n_hidden: \u001b[1;36m256\u001b[0m, n_latent: \u001b[1;36m20\u001b[0m, n_layers: \u001b[1;36m2\u001b[0m, dropout_rate: \u001b[1;36m0.2\u001b[0m, dispersion: gene, \n",
       "gene_likelihood: zinb\n",
       "Training status: Trained\n",
       "Model's adata is minified?: \u001b[3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Read reference and query data\n",
    "ref_adata = sc.read(\"BraunLinnarsson_2023_devbrain_hv2k.h5ad\")\n",
    "query_adata = sc.read(\"AminPasca_2023_organoid_screen_hv2k.h5ad\")\n",
    "\n",
    "# Format batch columns\n",
    "query_adata.obs[\"batch\"] = query_adata.obs[\"orig.ident\"].astype(str).copy()\n",
    "ref_adata.obs[\"batch\"] = ref_adata.obs[\"Donor\"].astype(str).copy()\n",
    "\n",
    "# Load reference model\n",
    "ref_model = scvi.model.SCANVI.load(\n",
    "    \"scarches_BraunLinnarsson/model.pt\",\n",
    "    adata=ref_adata,\n",
    ")\n",
    "\n",
    "print(ref_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `AtlasMapper` from HNOCA-tools to map the organoid data to the reference atlas. Under the hood this is using the transfer learning functionality of scANVI to finetune te model to the query dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m Found \u001b[1;36m100.0\u001b[0m% reference vars in query data.                                                                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m Training for \u001b[1;36m100\u001b[0m epochs.                                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100:  75%|███████▌  | 75/100 [02:06<00:41,  1.66s/it, v_num=1, train_loss_step=1.11e+3, train_loss_epoch=1.1e+3] "
     ]
    }
   ],
   "source": [
    "mapper = hmap.AtlasMapper(ref_model)\n",
    "mapper.map_query(query_adata, retrain=\"partial\", max_epochs=100, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
