{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome the Website of the Human Neural Organoid Cell Atlas (HNOCA)","text":"<p>The Human Neural Organoid Cell Atlas (HNOCA) is a collection of single-cell RNA-seq data from human brain organoids. The HNOCA is a resource for the scientific community to explore the cellular composition of human brain organoids and to understand the molecular mechanisms underlying brain development and disease.</p>"},{"location":"#installation","title":"Installation","text":"<p>HNOCA-tools can be installed using pip:</p> <pre><code>pip install hnoca\n</code></pre>"},{"location":"CHANGELOG/","title":"Changelog","text":"<p>Starting from version v0.2.0, all notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"CHANGELOG/#unreleased","title":"[Unreleased]","text":""},{"location":"CHANGELOG/#v021-2025-04-02","title":"v.0.2.1 (2025-04-02)","text":""},{"location":"CHANGELOG/#fixed","title":"Fixed","text":"<ul> <li>Release workflow to PyPI #12</li> </ul>"},{"location":"CHANGELOG/#v020-2025-04-01","title":"v.0.2.0 (2025-04-01)","text":""},{"location":"CHANGELOG/#added","title":"Added","text":"<ul> <li>Added a contribution guide to document how this package is set up #8.</li> <li>Added a <code>build.yaml</code> workflow to test whether the package can be build sucessfully #8.</li> <li>Added a <code>test.yaml</code> workflow to automate tests with github actions #8.</li> <li>Added pre-commit hooks via the <code>pyproject.toml</code> and <code>.pre-commit-config.yaml</code> files #8.</li> <li>Added the <code>pymdownx.tabbed</code> extension to <code>mkdocs</code> to display tabs in the docs #8.</li> <li>Added this Changelog #8.</li> <li>Added a <code>codecov.yaml</code> file, to configure coverage reports #8.</li> <li>Added a utility class in <code>utils/check</code> to check for optional dependencies #8.</li> <li>Added a basic logger #8.</li> <li>Added a check for snapseed to make sure that the marker dict has the right depth for annotate vs annotate_hierarchy #8.</li> <li>Added tests for snapseed #8.</li> <li>Set up pre-commit.ci</li> </ul>"},{"location":"CHANGELOG/#fixed_1","title":"Fixed","text":"<ul> <li>Fixed snapseed tests by reading leiden clustering from file #8.</li> </ul>"},{"location":"CHANGELOG/#changed","title":"Changed","text":"<ul> <li>The package now uses a <code>pyproject.toml</code> file to define the build system (hatch), dependencies, etc #8.</li> <li>Update the <code>publish.yaml</code> workflow in <code>release.yaml</code> #8.</li> <li>Moved code from <code>hnoca</code> to <code>src/hnoca</code> #8.</li> <li>Updated dependencies in <code>pyproject.toml</code>. Extra dependencies for <code>maping</code> and <code>stats</code> are optional, to ease installation #8.</li> <li>Use vcs-based versioning with hatch-vcs #10.</li> <li>Update the <code>build-site.yaml</code> workflow to run on PRs, and add package installation in the workflow using the <code>doc</code> option #9.</li> </ul>"},{"location":"CHANGELOG/#removed","title":"Removed","text":"<ul> <li>Removed the <code>black</code> badge from the <code>README.md</code>, as we did not automatically check for adherence to black code style #8.</li> <li>Removed the rendered docs in <code>docs</code> from git tracking, as it's not required and it yields unnecessary large git diffs when building the documentation locally #8.</li> </ul>"},{"location":"archmap/","title":"How to map query data to the HNOCA using ArchMap","text":"<p>Here we give a short overview of the relevant features of the ArchMap web service.</p> <p>Archmap is an easy-to-use web frontend that offers query-to-reference mapping for scRNA-seq datasets and interactive exploration of the results. It is, therefore, a great resource for mapping your new organoid dataset to the HNOCA or the fetal brain atlas by Braun et al.</p> <p>Please refer to the official ArchMap documentation for a general introduction and explanation of how to use ArchMap for query-to-reference mapping.</p>"},{"location":"archmap/#use-case-1-mapping-an-organoid-query-dataset-to-the-hnoca-with-archmap","title":"Use case 1: Mapping an organoid query dataset to the HNOCA with ArchMap","text":"<p>For quick contextualisation and annotation of your organoid datasets, you can use ArchMap to conveniently map it to the HNOCA. After creating your account, simply select the HNOCA from the ArchMap core reference atlases, select the scPoli model and a classifier (we recommend the KNN classifier for quick results), and upload your dataset. Please note the requirements listed on the submit page and adapt your adata object accordingly before uploading.</p> <p>Once the upload and processing has been completed, you can either download the mapped dataset or interactively explore the results through the inbuilt CellxGene interface.</p> <p>The following obs fields in the results object might be of interest:</p> <ul> <li>predictions_knn: here you can find the transferred HNOCA cell type labels for your query dataset</li> <li>type: this annotation lets you quickly distinguish your query dataset from the reference data</li> <li>Hallmark_Glycolysis: in the HNOCA paper, we introduce the concept of a metabolic stress score, which is specific to organoid datasets. ArchMap automatically computes this stress score for your query cells</li> <li>*_uncertainty_euclidean: this provides an uncertainty score per cell regarding the cell type label prediction found in predictions_knn</li> <li>presence_score: as introduced in the HNOCA paper, this score indicates, for every reference cell, how well that cell state is represented in your query dataset.</li> </ul>"},{"location":"archmap/#use-case-2-mapping-an-organoid-query-dataset-to-the-fetal-brain-atlas","title":"Use case 2: Mapping an organoid query dataset to the fetal brain atlas","text":"<p>If you want to contextualise your organoid dataset using the recent fetal brain atlas by Braun et al., you can follow the same steps as described above but select the fetal brain reference instead of HNOCA from the ArchMap Core Atlases.</p> <p>Note: Mapping organoid data to a primary reference is a challenging integration task, and the mapping might not be satisfactory depending on the query data. We are working on improving this.</p> <p>The following obs fields in the results object might be of interest:</p> <ul> <li>predictions_knn: here you can find the transferred HNOCA cell type labels for your query dataset</li> <li>type: this annotation lets you quickly distinguish your query dataset from the reference data</li> <li>*_uncertainty_euclidean: this provides an uncertainty score per cell regarding the cell type label prediction found in predictions_knn</li> <li>presence_score: as introduced in the HNOCA paper, this score indicates, for every reference cell, how well that cell state is represented in your query dataset.</li> </ul>"},{"location":"contributing/","title":"Contributing guide","text":"<p>Scanpy provides extensive developer documentation, most of which applies to this project, too. This document will not reproduce the entire content from there. Instead, it aims at summarizing the most important information to get you started on contributing.</p> <p>We assume that you are already familiar with git and with making pull requests on GitHub. If not, please refer to the scanpy developer guide.</p>"},{"location":"contributing/#installing-dev-dependencies","title":"Installing dev dependencies","text":"<p>In addition to the packages needed to use this package, you need additional python packages to run tests and build the documentation.</p> HatchPip <p>The easiest way is to get familiar with hatch environments, with which these tasks are simply:</p> <pre><code>hatch test  # defined in the [tool.hatch.envs.hatch-test] section in pyproject.toml\nhatch run docs:build  # defined in the [tool.hatch.envs.docs] section in pyproject.toml\n</code></pre> <p>If you prefer managing environments manually, you can use <code>pip</code>:</p> <pre><code>cd hnoca\npython3 -m venv .venv\nsource .venv/bin/activate\npip install -e \".[dev,test,doc]\"\n</code></pre>"},{"location":"contributing/#code-style","title":"Code-style","text":"<p>This package uses pre-commit to enforce consistent code styles. On every commit, pre-commit checks will either automatically fix issues with the code or raise an error message.</p> <p>To enable pre-commit locally, simply run</p> <pre><code>pre-commit install\n</code></pre> <p>in the root of the repository. Pre-commit will automatically download all dependencies when it is run for the first time.</p> <p>Alternatively, you can rely on the pre-commit.ci service enabled on GitHub. If you didn't run <code>pre-commit</code> before pushing changes to GitHub it will automatically commit fixes to your pull request or show an error message.</p> <p>If pre-commit.ci added a commit on a branch you have been working on locally, simply use</p> <pre><code>git pull --rebase\n</code></pre> <p>to integrate the changes into yours. While the pre-commit.ci service is useful, we strongly encourage installing and running pre-commit locally first to understand its usage.</p> <p>Finally, most editors have an autoformat on save feature. Consider enabling this option for ruff and prettier.</p>"},{"location":"contributing/#writing-tests","title":"Writing tests","text":"<p>This package uses pytest for automated testing. Please write {doc}<code>scanpy:dev/testing</code> for every function added to the package.</p> <p>Most IDEs integrate with pytest and provide a GUI to run tests. Just point yours to one of the environments returned by</p> <pre><code>hatch env create hatch-test  # create test environments for all supported versions\nhatch env find hatch-test  # list all possible test environment paths\n</code></pre> <p>Alternatively, you can run all tests from the command line by executing</p> HatchPip <pre><code>hatch test  # test with the highest supported Python version\n# or\nhatch test --all  # test with all supported Python versions\n</code></pre> <pre><code>source .venv/bin/activate\npytest\n</code></pre> <p>in the root of the repository.</p>"},{"location":"contributing/#continuous-integration","title":"Continuous integration","text":"<p>Continuous integration will automatically run the tests on all pull requests and test against the minimum and maximum supported Python versions.</p> <p>Additionally, there's a CI job that tests against pre-releases of all dependencies (if there are any). The purpose of this check is to detect incompatibilities of new package versions early on and gives you time to fix the issue or reach out to the developers of the dependency before the package is released to a wider audience.</p>"},{"location":"contributing/#publishing-a-release","title":"Publishing a release","text":""},{"location":"contributing/#updating-the-version-number","title":"Updating the version number","text":"<p>Version numbers in <code>pyproject.toml</code> are inferred automatically from git tags. Please adhere to Semantic Versioning. In brief:</p> <p>Given a version number MAJOR.MINOR.PATCH, increment the:</p> <ol> <li>MAJOR version when you make incompatible API changes,</li> <li>MINOR version when you add functionality in a backwards compatible manner, and</li> <li>PATCH version when you make backwards compatible bug fixes.</li> </ol> <p>Additional labels for pre-release and build metadata are available as extensions to the MAJOR.MINOR.PATCH format.</p> <p>Once you are done, commit and push your changes and navigate to the \"Releases\" page of this project on GitHub. Specify <code>vX.X.X</code> as a tag name and create a release. For more information, see managing GitHub releases. This will automatically create a git tag and trigger a GitHub workflow that creates a release on PyPI.</p>"},{"location":"contributing/#writing-documentation","title":"Writing Documentation","text":"<p>Please write documentation for new or changed features and use-cases. This project now uses MkDocs with the Material theme and a set of powerful plugins. Key features include:</p> <ul> <li> <p>Markdown-based Authoring:   All documentation is written in Markdown, keeping the content easy to read and maintain.</p> </li> <li> <p>Automatic API Reference:   The mkdocstrings plugin automatically generates API reference documentation from Python docstrings.</p> </li> <li> <p>Jupyter Notebook Integration:   With mknotebooks, you can seamlessly include and render Jupyter notebooks as part of your docs. This is ideal for tutorials and live examples.</p> </li> <li> <p>Enhanced Markdown Extensions:   The project leverages pymdown-extensions for improved code and content rendering. In particular, we use:</p> <ul> <li><code>pymdownx.highlight</code></li> <li><code>pymdownx.superfences</code></li> <li><code>pymdownx.inlinehilite</code></li> <li><code>pymdownx.tabbed</code></li> </ul> </li> <li> <p>Site Configuration:   The entire documentation setup\u2014including navigation, theme settings (logo, colors, etc.), and custom CSS\u2014is defined in the <code>mkdocs.yml</code> file.</p> </li> </ul> <p>For more insight on writing and maintaining documentation with MkDocs, please refer to the MkDocs User Guide.</p>"},{"location":"contributing/#tutorials-with-mkdocs-and-jupyter-notebooks","title":"Tutorials with MkDocs and Jupyter Notebooks","text":"<p>Our documentation integrates Jupyter notebooks using the mknotebooks plugin. Please ensure any notebooks you include are updated and re-run when necessary, so that both input and output cells remain current.</p>"},{"location":"contributing/#building-the-docs-locally","title":"Building the docs locally","text":"HatchPip <pre><code>hatch run docs:build\nhatch run docs:open\n</code></pre> <pre><code>source .venv/bin/activate\n# Build the static site\nmkdocs build\n# Serve the site locally\nmkdocs serve\n</code></pre>"},{"location":"quickstart/","title":"Human Neural Organoid Cell Atlas Toolbox","text":"<p>The HNOCA-tools package provides a set of tools we used to generate and analyze the Human Neural Organoid Cell Atlas (or other atlases, if you like). Among other things, it provides functions to:</p> <ul> <li>Rapidly annotate cell types based on marker genes</li> <li>Map query data to the reference atlas</li> <li>Transfer annotations between datasets</li> <li>Compute 'presence scores' for query data based on the reference atlas</li> <li>Perform differential expression analysis</li> </ul>"},{"location":"quickstart/#installation","title":"Installation","text":"<p>HNOCA-tools can be installed using <code>pip</code>:</p> <pre><code>pip install hnoca\n</code></pre>"},{"location":"quickstart/#quick-overview","title":"Quick overview","text":""},{"location":"quickstart/#annotation","title":"\ud83d\udd8b\ufe0f Annotation","text":"<p>We developed snapseed to rapidly annotate the HNOCA. It annotates cells based on manually defined sets of marker genes for individual cell types or cell type hierarchies. It is fast (i.e. GPU-accelerated) and simple to enable annotation of very large datasets.</p> <pre><code>import hnoca.snapseed as snap\nfrom hnoca.snapseed.utils import read_yaml\n\n# Read in the marker genes\nmarker_genes = read_yaml(\"marker_genes.yaml\")\n\n# Annotate anndata objects\nsnap.annotate(\n    adata,\n    marker_genes,\n    group_name=\"clusters\",\n    layer=\"lognorm\",\n)\n\n# Or for more complex hierarchies\nsnap.annotate_hierarchy(\n    adata,\n    marker_genes,\n    group_name=\"clusters\",\n    layer=\"lognorm\",\n)\n</code></pre>"},{"location":"quickstart/#mapping","title":"\ud83d\uddfa\ufe0f Mapping","text":"<p>For reference mapping, we mostly rely on scPoli and scANVI. Based on pretrained models, we here provide a simple interface to map query data to the reference atlas.</p> <pre><code>import scvi\nimport hnoca.map as mapping\n\n# Load the reference model\nref_model = scvi.model.SCANVI.load(\n    os.path.join(\"model.pt\"),\n    adata=ref_adata,\n)\n\n# Map query data\nmapper = mapping.AtlasMapper(ref_model)\nmapper.map_query(query_adata, retrain=\"partial\", max_epochs=100, batch_size=1024)\n</code></pre> <p>Now that the query dataset is mapped, we can perform kNN-based label transfer and presence score calculation.</p> <pre><code># Compute the weighted kNN\nmapper.compute_wknn(k=100)\n\n# Transfer labels\ncelltype_transfer = mapper.transfer_labels(label_key=\"cell_type\")\npresence_scores = mapper.get_presence_scores(split_by=\"batch\")\n</code></pre>"},{"location":"quickstart/#differential-expression","title":"\ud83d\udcca Differential expression","text":"<p>We have used ANOVA for DE analysis between the HNOCA and the reference atlas. Here, this is implemented as the <code>test_de()</code> function.</p> <pre><code>import hnoca.stats as stats\n\n# Perform DE analysis\nde_df = stats.test_de(\n    joint_adata,\n    group_key=\"origin\",\n    return_coef_group=\"organoid\",\n    adjust_method=\"holm\",\n)\n</code></pre> <p>In addition to DE testing on the atlas itself, we found it useful to treat the atlas as a universal \"control\" and test for DE w.r.t query datasets. For this, we first compute the matched expression profile for each cell in the query dataset and then test for DE using an F-test.</p> <pre><code># Compute matched expression profiles based on mapped data\nmatched_adata = mapper.get_matched_expression()\n\n# Perform DE analysis\nde_df = stats.test_de_paired(\n    query_adata,\n    matched_adata,\n    adjust_method=\"holm\",\n)\n</code></pre>"},{"location":"api/mapping/AtlasMapper/","title":"AtlasMapper","text":""},{"location":"api/mapping/AtlasMapper/#hnoca.mapping.mapper.AtlasMapper","title":"<code>hnoca.mapping.mapper.AtlasMapper(ref_model)</code>","text":"<p>A class to map a query dataset to a reference dataset using scPoli, scVI or scANVI models.</p> <p>Parameters:</p> Name Type Description Default <code>ref_model</code> <code>SCANVI | SCVI | scPoli</code> <p>The reference model to map the query dataset to.</p> required"},{"location":"api/mapping/AtlasMapper/#hnoca.mapping.mapper.AtlasMapper.map_query","title":"<code>map_query(query_adata, retrain='partial', labeled_indices=None, **kwargs)</code>","text":"<p>Map a query dataset to the reference dataset</p> <p>Parameters:</p> Name Type Description Default <code>query_adata</code> <code>AnnData</code> <p>The query dataset to map to the reference dataset</p> required <code>retrain</code> <code>Literal['partial', 'full', 'none']</code> <p>Whether to retrain the query model.</p> <ul> <li><code>\"partial\"</code> will retrain the weights of the new batch key</li> <li><code>\"full\"</code> will retrain the entire model</li> <li><code>\"none\"</code> will use the reference model without retraining</li> </ul> <code>'partial'</code> <code>labeled_indices</code> <code>ndarray | None</code> <p>The indices of labeled cells in the query dataset. This is only used for scPoli models.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the training function</p> <code>{}</code>"},{"location":"api/mapping/AtlasMapper/#hnoca.mapping.mapper.AtlasMapper.compute_wknn","title":"<code>compute_wknn(ref_adata=None, k=100, query2ref=True, ref2query=False, ref_rep_key='X_latent', query_rep_key='X_latent', weighting_scheme='jaccard_square', top_n=None)</code>","text":"<p>Compute the weighted k-nearest neighbors graph between the reference and query datasets</p> <p>Parameters:</p> Name Type Description Default <code>k</code> <code>int</code> <p>Number of neighbors per cell</p> <code>100</code> <code>query2ref</code> <code>bool</code> <p>Consider query-to-ref neighbors</p> <code>True</code> <code>ref2query</code> <code>bool</code> <p>Consider ref-to-query neighbors</p> <code>False</code> <code>weighting_scheme</code> <code>Literal['n', 'top_n', 'jaccard', 'jaccard_square', 'gaussian', 'dist']</code> <p>How to weight edges in the ref-query neighbor graph</p> <code>'jaccard_square'</code> <code>top_n</code> <code>int | None</code> <p>The number of top neighbors to consider</p> <code>None</code>"},{"location":"api/mapping/AtlasMapper/#hnoca.mapping.mapper.AtlasMapper.get_presence_scores","title":"<code>get_presence_scores(split_by=None, random_walk=True, alpha=0.1, n_rounds=100, log=True)</code>","text":"<p>Estimate the presence score of the query dataset</p> <p>Parameters:</p> Name Type Description Default <code>split_by</code> <code>str | None</code> <p>The column in the query dataset to split by</p> <code>None</code> <code>random_walk</code> <code>bool</code> <p>Whether to use random walk to estimate presence score</p> <code>True</code> <code>alpha</code> <code>float</code> <p>The heat diffusion parameter for the random walk</p> <code>0.1</code> <code>n_rounds</code> <code>int</code> <p>The number of rounds for the random walk</p> <code>100</code> <code>log</code> <code>bool</code> <p>Whether to log the presence score</p> <code>True</code>"},{"location":"api/mapping/AtlasMapper/#hnoca.mapping.mapper.AtlasMapper.get_presence_scores--returns","title":"Returns","text":"<pre><code>A dictionary with the presence scores\n</code></pre>"},{"location":"api/mapping/AtlasMapper/#hnoca.mapping.mapper.AtlasMapper.transfer_labels","title":"<code>transfer_labels(label_key)</code>","text":"<p>Transfer labels from the reference dataset to the query dataset</p> <p>Parameters:</p> Name Type Description Default <code>label_key</code> <code>str</code> <p>str The column in the reference dataset to transfer</p> required"},{"location":"api/mapping/AtlasMapper/#hnoca.mapping.mapper.AtlasMapper.transfer_labels--returns","title":"Returns","text":"<pre><code>A dictionary with the transfer scores\n</code></pre>"},{"location":"api/mapping/AtlasMapper/#hnoca.mapping.mapper.AtlasMapper.get_matched_expression","title":"<code>get_matched_expression(rescale_factor=1)</code>","text":"<p>Get the expression of reference cells matched to query cells. This can be used for quantitative comparisons like DE analysis.</p> <p>Parameters:</p> Name Type Description Default <code>rescale_factor</code> <code>int</code> <p>str Factor to rescale the log-normalized counts</p> <code>1</code>"},{"location":"api/mapping/AtlasMapper/#hnoca.mapping.mapper.AtlasMapper.get_matched_expression--returns","title":"Returns","text":"<pre><code>An AnnData object with the matched expression\n</code></pre>"},{"location":"api/mapping/AtlasMapper/#hnoca.mapping.mapper.AtlasMapper.save","title":"<code>save(output_dir)</code>","text":"<p>Save the mapper object to disk</p> <p>Parameters:</p> Name Type Description Default <code>output_dir</code> <code>str</code> <p>str The directory to save the mapper object</p> required"},{"location":"api/mapping/AtlasMapper/#hnoca.mapping.mapper.AtlasMapper.load","title":"<code>load(input_dir)</code>  <code>classmethod</code>","text":"<p>Load the mapper object from disk</p> <p>Parameters:</p> Name Type Description Default <code>input_dir</code> <code>str</code> <p>str The directory to load the mapper object</p> required"},{"location":"api/snapseed/annotate/","title":"annotate","text":""},{"location":"api/snapseed/annotate/#hnoca.snapseed.annotate.annotate","title":"<code>hnoca.snapseed.annotate.annotate(adata, marker_dict, group_name, layer=None, **kwargs)</code>","text":"<p>Annotate clusters based on a manually defined cell type markers.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>AnnData object</p> required <code>marker_dict</code> <code>dict</code> <p>Dict with marker genes for each celltype</p> required <code>group_name</code> <code>str</code> <p>Name of the column in adata.obs that contains the cluster labels</p> required <code>layer</code> <code>str | None</code> <p>Layer in adata to use for expression</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments to pass to the annotation function.</p> <code>{}</code>"},{"location":"api/snapseed/annotate/#hnoca.snapseed.annotate.annotate--returns","title":"Returns","text":"<pre><code>pd.DataFrame with assignments\n</code></pre>"},{"location":"api/snapseed/annotate_hierarchy/","title":"annotate_hierarchy","text":""},{"location":"api/snapseed/annotate_hierarchy/#hnoca.snapseed.annotate.annotate_hierarchy","title":"<code>hnoca.snapseed.annotate.annotate_hierarchy(adata, marker_hierarchy, group_name, layer=None, min_expr=0.1, **kwargs)</code>","text":"<p>Annotate clusters based on a manually defined cell type and marker hierarchy.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>AnnData object</p> required <code>marker_hierarchy</code> <code>dict</code> <p>dict arker genes for each celltype arranged hierarchically.</p> required <code>group_name</code> <code>str</code> <p>Name of the column in adata.obs that contains the cluster labels</p> required <code>layer</code> <code>str | None</code> <p>Layer in adata to use for expression</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments to pass to the annotation function.</p> <code>{}</code>"},{"location":"api/snapseed/annotate_hierarchy/#hnoca.snapseed.annotate.annotate_hierarchy--returns","title":"Returns","text":"<pre><code>Dict with assignments and metrics\n</code></pre>"},{"location":"api/snapseed/find_markers/","title":"find_markers","text":""},{"location":"api/snapseed/find_markers/#hnoca.snapseed.markers.find_markers","title":"<code>hnoca.snapseed.markers.find_markers(adata, group_name, features=None, layer=None)</code>","text":"<p>Find markers for each cluster.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>AnnData object</p> required <code>group_name</code> <code>str</code> <p>Name of the column in adata.obs that contains the cluster labels</p> required <code>features</code> <code>list | None</code> <p>List of features to use for marker identification</p> <code>None</code> <code>layer</code> <code>str | None</code> <p>Layer in adata to use for expression</p> <code>None</code>"},{"location":"api/snapseed/find_markers/#hnoca.snapseed.markers.find_markers--returns","title":"Returns","text":"<pre><code>A `pd.DataFrame` with AUROC and detection ratio for each gene and cluster.\n</code></pre>"},{"location":"api/stats/create_pseudobulk/","title":"create_pseudobulk","text":""},{"location":"api/stats/create_pseudobulk/#hnoca.stats.pseudobulk.create_pseudobulk","title":"<code>hnoca.stats.pseudobulk.create_pseudobulk(adata, sample_key='batch', group_key=None, layer=None, mode='sum', min_cells=10, min_counts=1000, **kwargs)</code>","text":"<p>Create pseudobulk data from anndata object</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>AnnData object</p> required <code>sample_key</code> <code>str</code> <p>Column name in adata.obs that contains the sample ID</p> <code>'batch'</code> <code>group_key</code> <code>str | None</code> <p>Column name in adata.obs that contains the group ID</p> <code>None</code> <code>layer</code> <code>str | None</code> <p>Layer to use for pseudobulk data. If None, use <code>adata.X</code></p> <code>None</code> <code>mode</code> <code>str</code> <p>Method to aggregate data. Default is 'sum'.</p> <code>'sum'</code> <code>min_cells</code> <code>int</code> <p>Filter to remove samples by a minimum number of cells in a sample-group pair.</p> <code>10</code> <code>min_counts</code> <code>int</code> <p>Filter to remove samples by a minimum number of summed counts in a sample-group pair.</p> <code>1000</code> <code>**kwargs</code> <p>Additional arguments to pass to <code>decoupler.get_pseudobulk()</code></p> <code>{}</code>"},{"location":"api/stats/create_pseudobulk/#hnoca.stats.pseudobulk.create_pseudobulk--returns","title":"Returns","text":"<pre><code>AnnData object with pseudobulk data\n</code></pre>"},{"location":"api/stats/test_de/","title":"test_de","text":""},{"location":"api/stats/test_de/#hnoca.stats.de.test_de","title":"<code>hnoca.stats.de.test_de(adata, group, covar, num_threads=1, return_coef_group=None, var_names=None, adjust_method='holm')</code>","text":"<p>Test for differential expression using ANOVA</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>AnnData object</p> required <code>group</code> <code>str | Series</code> <p>str or pd.Series The group labels</p> required <code>covar</code> <code>str | DataFrame</code> <p>str or pd.DataFrame The covariates</p> required <code>num_threads</code> <code>int</code> <p>int The number of threads to use</p> <code>1</code> <code>return_coef_group</code> <code>str | None</code> <p>str The group to return coefficients for</p> <code>None</code> <code>var_names</code> <code>list | None</code> <p>list The variable names to test</p> <code>None</code> <code>adjust_method</code> <code>str</code> <p>str The method to adjust p-values. See https://www.statsmodels.org/dev/generated/statsmodels.stats.multitest.multipletests.html</p> <code>'holm'</code>"},{"location":"api/stats/test_de/#hnoca.stats.de.test_de--returns","title":"Returns","text":"<pre><code>A `pd.DataFrame` with the differential expression results\n</code></pre>"},{"location":"api/stats/test_de_paired/","title":"test_de_paired","text":""},{"location":"api/stats/test_de_paired/#hnoca.stats.de.test_de_paired","title":"<code>hnoca.stats.de.test_de_paired(query_adata, matched_adata, covar=None, num_threads=1, var_names=None, adjust_method='holm')</code>","text":"<p>Test for differential expression between query data and matches reference cells using an F-test.</p> <p>Parameters:</p> Name Type Description Default <code>query_adata</code> <code>AnnData</code> <p>AnnData object The query data</p> required <code>matched_adata</code> <code>AnnData</code> <p>AnnData object The matched reference data</p> required <code>covar</code> <code>str | DataFrame | None</code> <p>str or pd.DataFrame The covariates</p> <code>None</code> <code>num_threads</code> <code>int</code> <p>int The number of threads to use</p> <code>1</code> <code>var_names</code> <code>list | None</code> <p>list The variable names to test</p> <code>None</code> <code>adjust_method</code> <code>str</code> <p>str The method to adjust p-values. See https://www.statsmodels.org/dev/generated/statsmodels.stats.multitest.multipletests.html</p> <code>'holm'</code>"},{"location":"api/stats/test_de_paired/#hnoca.stats.de.test_de_paired--returns","title":"Returns","text":"<pre><code>A `pd.DataFrame` with the differential expression results\n</code></pre>"},{"location":"api/utils/compute_glycolysis_score/","title":"compute_glycolysis_score","text":""},{"location":"api/utils/compute_glycolysis_score/#hnoca.utils.stress.compute_glycolysis_score","title":"<code>hnoca.utils.stress.compute_glycolysis_score(adata, **kwargs)</code>","text":"<p>Compute glycolysis score using hallmark glycolysis genes from MSigDB.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Anndata object with gene expression data.</p> required <code>**kwargs</code> <p>Additional arguments passed to <code>sc.tl.score_genes</code>.</p> <code>{}</code>"},{"location":"api/utils/compute_glycolysis_score/#hnoca.utils.stress.compute_glycolysis_score--returns","title":"Returns","text":"<pre><code>`None`. The glycolysis score is stored in `adata.obs[\"Hallmark_Glycolysis\"]`.\n</code></pre>"},{"location":"vignettes/annotation/","title":"Annotation","text":"<pre><code>import os\n\nimport scanpy as sc\nfrom flax.core.frozen_dict import FrozenDict\n\nimport hnoca.snapseed as snap\nfrom hnoca.snapseed.utils import read_yaml\n\nos.chdir(\"/home/fleckj/scratch/hnoca/\")\n</code></pre> <pre><code># Read input data\nhnoca_adata = sc.read(\"HNOCA_hv2k.h5ad\")\nprint(hnoca_adata)\n</code></pre> <pre>\n<code>AnnData object with n_obs \u00d7 n_vars = 1770578 \u00d7 2000\n    obs: 'assay_sc', 'assay_differentiation', 'assay_type_differentiation', 'bio_sample', 'cell_line', 'cell_type', 'development_stage', 'disease', 'ethnicity', 'gm', 'id', 'individual', 'organ', 'organism', 'sex', 'state_exact', 'sample_source', 'source_doi', 'suspension_type_original', 'tech_sample', 'treatment', 'assay_sc_original', 'cell_line_original', 'cell_type_original', 'development_stage_original', 'disease_original', 'ethnicity_original', 'organ_original', 'organism_original', 'sex_original', 'suspension_type', 'obs_names_original', 'organoid_age_days', 'publication', 'doi', 'batch', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'total_counts_mt', 'log1p_total_counts_mt', 'pct_counts_mt', 'leiden_pca_unintegrated_1', 'leiden_pca_unintegrated_80', 'leiden_pca_rss_1', 'leiden_pca_rss_80', 'snapseed_pca_unintegrated_level_1', 'snapseed_pca_unintegrated_level_2', 'snapseed_pca_unintegrated_level_3', 'snapseed_pca_unintegrated_level_4', 'snapseed_pca_unintegrated_level_5', 'snapseed_pca_unintegrated_level_12', 'snapseed_pca_unintegrated_level_123', 'snapseed_pca_unintegrated_level_1234', 'snapseed_pca_unintegrated_level_12345', 'snapseed_pca_rss_level_1', 'snapseed_pca_rss_level_2', 'snapseed_pca_rss_level_3', 'snapseed_pca_rss_level_4', 'snapseed_pca_rss_level_5', 'snapseed_pca_rss_level_12', 'snapseed_pca_rss_level_123', 'snapseed_pca_rss_level_1234', 'snapseed_pca_rss_level_12345', 'leiden_scpoli_1', 'leiden_scpoli_80', 'snapseed_scpoli_level_1', 'snapseed_scpoli_level_2', 'snapseed_scpoli_level_3', 'snapseed_scpoli_level_4', 'snapseed_scpoli_level_5', 'snapseed_scpoli_level_12', 'snapseed_scpoli_level_123', 'snapseed_scpoli_level_1234', 'snapseed_scpoli_level_12345', 'annot_region_rev2', 'annot_level_3_rev2', 'annot_level_4_rev2', 'annot_ntt_rev2'\n    var: 'ensembl', 'gene_symbol', 'mt', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'gene_length', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'highly_variable_nbatches'\n    uns: 'annot_region_rev2_colors', 'hvg', 'knn_pca_rss', 'knn_pca_unintegrated', 'knn_scpoli', 'log1p'\n    obsm: 'X_pca_rss', 'X_pca_unintegrated', 'X_rss', 'X_scpoli', 'X_umap_pca_rss', 'X_umap_pca_unintegrated', 'X_umap_scpoli'\n    layers: 'counts', 'counts_lengthnorm', 'lognorm'\n    obsp: 'knn_pca_rss_connectivities', 'knn_pca_rss_distances', 'knn_pca_unintegrated_connectivities', 'knn_pca_unintegrated_distances', 'knn_scpoli_connectivities', 'knn_scpoli_distances'\n</code>\n</pre> <p>In it's most basic form, snapeed takes adata object and a dict with marker genes for different cell types. A very simple example might look like this:</p> <pre><code>marker_dict = {\n    \"neuron\": [\"STMN2\", \"DCX\"],\n    \"progenitor\": [\"SOX2\", \"VIM\", \"NES\"],\n}\n\nassignments = snap.annotate(hnoca_adata, marker_dict, group_name=\"leiden_pca_rss_80\")\nassignments = assignments.set_index(\"leiden_pca_rss_80\")\n</code></pre> <p>The output of snapseed is a pandas dataframe with annotations for each cluster. We can join this information back to the adata object to visualize the annotations on the single-cell level.  </p> <pre><code>cell_assign = assignments.loc[hnoca_adata.obs[\"leiden_pca_rss_80\"].astype(str).values, :]\nhnoca_adata.obs[\"snap_class\"] = cell_assign[\"class\"].values\n\n# Plot the annotations\nsc.pl.scatter(hnoca_adata, color=[\"snap_class\", \"STMN2\", \"VIM\"], basis=\"umap_scpoli\")\n</code></pre> <p>This looks quite reasonable, so let's make it a bit more interesting. In practice, cell type annotations are often hierachical, so we might want to take this into account in the annotation process. For example, we can first annotate progenitors and neurons and then split them up into more fine-grained subtypes and regional identities. </p> <p>Snapseed allows this by recusively annotating cells based on a hierarchy of cell types and marker genes. Such a hierarchy can be provided as a YAML file like this one:</p> <p>(The <code>FrozenDict</code> is just to enable better printing of a large dictionary)</p> <pre><code>marker_hierarchy = read_yaml(\"brain_markers.yaml\")\nprint(FrozenDict(marker_hierarchy))\n</code></pre> <pre>\n<code>FrozenDict({\n    neural_progenitor_cell: {\n        marker_genes: ['SOX2', 'VIM', 'NES'],\n        subtypes: {\n            glioblast: {\n                marker_genes: ['HOPX', 'BCAN', 'TNC'],\n            },\n            telencephalic_npc: {\n                marker_genes: ['FOXG1'],\n                subtypes: {\n                    dorsal_npc: {\n                        marker_genes: ['EMX1'],\n                    },\n                    hippocampal_npc: {\n                        marker_genes: ['GABRA2', 'GABRB1'],\n                    },\n                    ventral_npc: {\n                        marker_genes: ['DLX2'],\n                    },\n                },\n            },\n            diencephalic_npc: {\n                marker_genes: ['TCF7L2', 'SIX3'],\n                subtypes: {\n                    hypothalamic_npc: {\n                        marker_genes: ['SIX3'],\n                    },\n                    thalamic_npc: {\n                        marker_genes: ['TCF7L2'],\n                    },\n                },\n            },\n            mesencephalic_npc: {\n                marker_genes: ['OTX2', 'PAX7'],\n            },\n            retinal_npc: {\n                marker_genes: ['VSX2'],\n            },\n            rhombencephalic_npc: {\n                marker_genes: ['CYP26A1', 'HOXA2', 'HOXB2', 'UNC5C', 'BCAN'],\n                subtypes: {\n                    cerebellar_npc: {\n                        marker_genes: ['UNC5C', 'CYP26A1'],\n                    },\n                    pons_npc: {\n                        marker_genes: ['GPC6', 'BCAN'],\n                    },\n                    medullary_npc: {\n                        marker_genes: ['HOXB2', 'HOXD3', 'HOXA3'],\n                    },\n                },\n            },\n        },\n    },\n    neuron: {\n        marker_genes: ['STMN2', 'DCX'],\n        subtypes: {\n            excitatory_neuron: {\n                marker_genes: ['SLC17A7', 'SLC17A6'],\n                subtypes: {\n                    telencephalic_excitatory_neuron: {\n                        marker_genes: ['FOXG1', 'EMX1', 'SLC17A7'],\n                        subtypes: {\n                            deeper_layer_cortical_excitatory_neuron: {\n                                marker_genes: ['BCL11B'],\n                            },\n                            upper_layer_cortical_excitatory_neuron: {\n                                marker_genes: ['SATB2'],\n                            },\n                            hippocampal_excitatory_neuron: {\n                                marker_genes: ['GABRA2', 'GABRB1'],\n                            },\n                        },\n                    },\n                    non_telencephalic_excitatory_neuron: {\n                        marker_genes: ['SLC17A6'],\n                        subtypes: {\n                            diencephalic_excitatory_neuron: {\n                                marker_genes: ['TCF7L2', 'PITX2'],\n                                subtypes: {\n                                    hypothalamic_excitatory_neuron: {\n                                        marker_genes: ['PITX2'],\n                                    },\n                                    thalamic_excitatory_neuron: {\n                                        marker_genes: ['TCF7L2'],\n                                    },\n                                },\n                            },\n                            mesencephalic_excitatory_neuron: {\n                                marker_genes: ['BARHL2', 'TFAP2D'],\n                            },\n                            rhombencephalic_excitatory_neuron: {\n                                marker_genes: ['TFAP2A', 'HOXA2', 'HOXB2', 'HOXB2', 'HOXD3', 'HOXA3'],\n                                subtypes: {\n                                    cerebellar_excitatory_neuron: {\n                                        marker_genes: ['UNCX', 'INSM1', 'UNC5C'],\n                                    },\n                                    pons_excitatory_neuron: {\n                                        marker_genes: ['ROBO1', 'NEGR1'],\n                                    },\n                                    medullary_excitatory_neuron: {\n                                        marker_genes: ['HOXB2', 'HOXD3', 'HOXA3'],\n                                    },\n                                },\n                            },\n                        },\n                    },\n                },\n            },\n            inhibitory_neuron: {\n                marker_genes: ['GAD1', 'GAD2', 'SLC32A1'],\n                subtypes: {\n                    telencephalic_inhibitory_neuron: {\n                        marker_genes: ['FOXG1'],\n                        subtypes: {\n                            ventral_inhibitory_neuron: {\n                                marker_genes: ['DLX2', 'DLX5'],\n                                subtypes: {\n                                    mge_inhibitory_neuron: {\n                                        marker_genes: ['NKX2-1'],\n                                    },\n                                    lge_inhibitory_neuron: {\n                                        marker_genes: ['ISL1'],\n                                    },\n                                    cge_inhibitory_neuron: {\n                                        marker_genes: ['NR2F1'],\n                                    },\n                                },\n                            },\n                        },\n                    },\n                    non_telencephalic_inhibitory_neuron: {\n                        marker_genes: ['LHX5', 'LHX1'],\n                        subtypes: {\n                            diencephalic_inhibitory_neuron: {\n                                marker_genes: ['TCF7L2', 'ISL1'],\n                                subtypes: {\n                                    hypothalamic_inhibitory_neuron: {\n                                        marker_genes: ['ISL1'],\n                                    },\n                                    thalamic_inhibitory_neuron: {\n                                        marker_genes: ['DLX1', 'DLX5'],\n                                    },\n                                },\n                            },\n                            mesencephalic_inhibitory_neuron: {\n                                marker_genes: ['OTX2'],\n                            },\n                            rhombencephalic_inhibitory_neuron: {\n                                marker_genes: ['SKOR2', 'HOXA2', 'HOXB2', 'CA8', 'LAMP5'],\n                                subtypes: {\n                                    cerebellar_inhibitory_neuron: {\n                                        marker_genes: ['CA8', 'TFAP2A', 'SKOR2', 'UNC5C'],\n                                    },\n                                    medullary_inhibitory_neuron: {\n                                        marker_genes: ['HOXB2', 'HOXD3', 'HOXA3', 'LAMP5'],\n                                    },\n                                    pons_inhibitory_neuron: {\n                                        marker_genes: ['ROBO1', 'NEGR1'],\n                                    },\n                                },\n                            },\n                        },\n                    },\n                },\n            },\n        },\n    },\n    choroid_plexus_epithelium: {\n        marker_genes: ['TTR'],\n    },\n    astrocyte: {\n        marker_genes: ['GFAP', 'AQP4'],\n    },\n    oligodendrocyte_lineage: {\n        marker_genes: ['OLIG1', 'MBP'],\n        subtypes: {\n            oligodendrocyte_precursor_cell: {\n                marker_genes: ['OLIG1'],\n            },\n            mature_oligodendrocyte: {\n                marker_genes: ['MBP'],\n            },\n        },\n    },\n    microglia: {\n        marker_genes: ['AIF1'],\n    },\n    vascular_endothelial_cell: {\n        marker_genes: ['CLDN5'],\n    },\n    mesenchymal_cell: {\n        marker_genes: ['DCN'],\n    },\n    neural_crest: {\n        marker_genes: ['SOX10'],\n    },\n    pns_neurons: {\n        marker_genes: ['PRPH'],\n    },\n})\n</code>\n</pre> <pre><code>assignments = snap.annotate_hierarchy(hnoca_adata, marker_hierarchy, group_name=\"leiden_pca_rss_80\")\n</code></pre> <p>Now, snapseeds outputs a dictionary with the assignment dataframe, as well as the hierarchy. Again, we can plot the result as in a UMAP.</p> <pre><code>cell_assign = assignments[\"assignments\"].loc[hnoca_adata.obs[\"leiden_pca_rss_80\"].astype(str).values, :]\nhnoca_adata.obs[\"snap_level_1\"] = cell_assign[\"level_1\"].values\nhnoca_adata.obs[\"snap_level_2\"] = cell_assign[\"level_2\"].values\nhnoca_adata.obs[\"snap_level_3\"] = cell_assign[\"level_3\"].values\n\n# Plot the annotations\nsc.pl.scatter(hnoca_adata, color=[\"snap_level_1\", \"snap_level_2\", \"snap_level_3\"], basis=\"umap_scpoli\")\n</code></pre> <p>Here, snapseed gives annotations for each level of the provided hierarchy. </p>"},{"location":"vignettes/annotation/#atlas-annotation-with-snapseed","title":"Atlas annotation with snapseed","text":"<p>We developed snapseed to quickly provide marker-based annotations on large datasets. This can be very handy to provide \"seed annotations\" for label-dependent integration methods such as scANVI or scPoli. </p> <p>Snapseed is based on the idea that a marker gene of a cell type should be specific for that cell type and should be expressed in a large fraction of the cells of that type. As a measure of specificity, snapseed computes single-feature ROC-AUC scores for each marker gene in each cluster. Together with the fraction of cells expressing the gene, we obtain a score that is used to assign clusters to cell types. </p> <p>In this notebook, we'll showcase how to use snapseed to annotate cell types in the Human Neural Organoid Atlas dataset.  </p>"},{"location":"vignettes/atlas_mapping/","title":"Mapping to the HNOCA","text":"<pre><code>import os\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scanpy as sc\nimport scarches\n\nimport hnoca.mapping as hmap\nimport hnoca.stats as stats\n\nos.chdir(\"/home/fleckj/scratch/hnoca/\")\n</code></pre> <pre><code># Read reference and query data\nhnoca_adata = sc.read(\"HNOCA_hv3k.h5ad\")\nquery_adata = sc.read(\"KangWen2021_FXS.h5ad\")\n\n# Format batch columns\nquery_adata.obs[\"batch\"] = query_adata.obs[\"sample\"].astype(str).copy()\n\n# Load reference model\nhnoca_model = scarches.models.scPoli.load(\n    \"scpoli_HNOCA/\",\n    adata=hnoca_adata,\n)\nprint(hnoca_model)\n</code></pre> <pre>\n<code>AnnData object with n_obs \u00d7 n_vars = 1751568 \u00d7 3000\n    obs: 'assay_sc', 'assay_differentiation', 'assay_type_differentiation', 'bio_sample', 'cell_line', 'cell_type', 'development_stage', 'disease', 'ethnicity', 'gm', 'id', 'individual', 'organ', 'organism', 'sex', 'state_exact', 'sample_source', 'source_doi', 'suspension_type_original', 'tech_sample', 'treatment', 'assay_sc_original', 'cell_line_original', 'cell_type_original', 'development_stage_original', 'disease_original', 'ethnicity_original', 'organ_original', 'organism_original', 'sex_original', 'suspension_type', 'obs_names_original', 'organoid_age_days', 'batch', 'publication', 'doi', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'log_n_genes_by_counts', 'log1p_pct_counts_mt', 'leiden_1', 'leiden_10', 'leiden_pca_1', 'leiden_pca_10', 'leiden_20', 'leiden_80', 'leiden_pca_20', 'leiden_pca_80', 'snap_clusters', 'snap_clusters_pca', 'level_1_pca', 'level_2_pca', 'level_3_pca', 'level_4_pca', 'level_5_pca', 'level_12_pca', 'level_123_pca', 'level_1234_pca', 'level_12345_pca', 'leiden_80_scpoli_h123', 'level_1_rss', 'level_2_rss', 'level_3_rss', 'level_4_rss', 'level_5_rss', 'level_12_rss', 'level_123_rss', 'level_1234_rss', 'level_12345_rss', 'level_12', 'level_123', 'level_1234', 'level_12345', 'braun_projected_class', 'braun_projected_region', 'level_1', 'level_2', 'level_3', 'level_4', 'level_5'\n    var: 'ensembl', 'gene_symbol', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'gene_length', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n    uns: 'assay_sc_colors', 'braun_projected_class_colors', 'braun_projected_region_colors', 'hvg', 'knn_aggrecell_scpoli_level1', 'knn_pca', 'knn_rss_pca', 'knn_scanvi_level1', 'knn_scanvi_level2', 'knn_scanvi_level3', 'knn_scanvi_pcaclust', 'knn_scpoli_hierarchical123', 'knn_scpoli_level1', 'knn_scpoli_level1_pcaclust', 'knn_scpoli_level2', 'knn_scpoli_level3', 'knn_scvi', 'leiden', 'level_12345_colors', 'level_1234_colors', 'level_123_colors', 'level_123_rss_colors', 'level_123_rss_sizes', 'level_123_sizes', 'level_12_colors', 'level_1_colors', 'level_2_colors', 'level_3_colors', 'level_3_rss_colors', 'level_5_colors', 'log1p', 'neighbors', 'paga', 'publication_colors', 'umap'\n    obsm: 'X_aggrecell_scpoli_level1', 'X_pca', 'X_rss', 'X_rss_pca', 'X_scanvi_level1', 'X_scanvi_level1_pcaclust', 'X_scanvi_level2', 'X_scanvi_level3', 'X_scpoli_hierarchical123', 'X_scpoli_level1', 'X_scpoli_level1_pcaclust', 'X_scpoli_level2', 'X_scpoli_level3', 'X_scvi', 'X_umap', 'X_umap_aggrecell_scpoli_level1', 'X_umap_pca', 'X_umap_rss_pca', 'X_umap_scanvi_level1', 'X_umap_scanvi_level2', 'X_umap_scanvi_level3', 'X_umap_scanvi_pcaclust', 'X_umap_scpoli_hierarchical123', 'X_umap_scpoli_level1', 'X_umap_scpoli_level1_pcaclust', 'X_umap_scpoli_level2', 'X_umap_scpoli_level3', 'X_umap_scvi'\n    layers: 'counts'\n    obsp: 'connectivities', 'distances', 'knn_aggrecell_scpoli_level1_connectivities', 'knn_aggrecell_scpoli_level1_distances', 'knn_pca_connectivities', 'knn_pca_distances', 'knn_rss_pca_connectivities', 'knn_rss_pca_distances', 'knn_scanvi_level1_connectivities', 'knn_scanvi_level1_distances', 'knn_scanvi_level2_connectivities', 'knn_scanvi_level2_distances', 'knn_scanvi_level3_connectivities', 'knn_scanvi_level3_distances', 'knn_scanvi_pcaclust_connectivities', 'knn_scanvi_pcaclust_distances', 'knn_scpoli_hierarchical123_connectivities', 'knn_scpoli_hierarchical123_distances', 'knn_scpoli_level1_connectivities', 'knn_scpoli_level1_distances', 'knn_scpoli_level1_pcaclust_connectivities', 'knn_scpoli_level1_pcaclust_distances', 'knn_scpoli_level2_connectivities', 'knn_scpoli_level2_distances', 'knn_scpoli_level3_connectivities', 'knn_scpoli_level3_distances', 'knn_scvi_connectivities', 'knn_scvi_distances'\nEmbedding dictionary:\n    Num conditions: [396]\n    Embedding dim: [5]\nEncoder Architecture:\n    Input Layer in, out and cond: 3000 1024 5\n    Mean/Var Layer in/out: 1024 10\nDecoder Architecture:\n    First Layer in, out and cond:  10 1024 5\n    Output Layer in/out:  1024 3000 \n\n&lt;scarches.models.scpoli.scpoli_model.scPoli object at 0x14bda502a4a0&gt;\n</code>\n</pre> <p>Now we have eveything together to start the reference mapping. Here we are finetuning the HNOCA scPoli model for 30 epochs (<code>n_epochs</code>) retraining only the weights for the new batch covariates (<code>retrain=\"partial\"</code>). </p> <pre><code>mapper = hmap.AtlasMapper(hnoca_model)\nmapper.map_query(query_adata, retrain=\"partial\", n_epochs=30, pretraining_epochs=20, eta=10, batch_size=1024)\nmapper.save(\"HNOCA_FXS_mapper/\")\n</code></pre> <p>With this finetuned model we can then compute a weighted kNN graph between the query and reference data.</p> <pre><code>mapper = hmap.AtlasMapper.load(\"HNOCA_FXS_mapper/\")\n</code></pre> <pre><code>mapper.compute_wknn(k=100)\n</code></pre> <p>Using the wkNN graph, we can now transfer cell type labels from the HNOCA to the query data and compute a UMAP from the latent space of the scPoli model.</p> <pre><code>ct_transfer = mapper.transfer_labels(label_key=\"level_1_pca\")\nct_transfer[[\"best_label\", \"best_score\"]]\n</code></pre> best_label best_score AAACCCACAGTTCCAA.4 neural_progenitor_cell 0.831662 AAACCCAGTTGCATCA.4 neural_progenitor_cell 1.733664 AAACCCAGTTGCATTG.4 neural_progenitor_cell 2.297948 AAACCCATCCACGTGG.4 neuron 1.610558 AAACGAACACAGTGAG.4 neuron 0.854941 ... ... ... TTTGGTTGTCACCCTT.12 choroid_plexus_epithelium 1.629327 TTTGTTGAGACCTTTG.12 choroid_plexus_epithelium 0.321833 TTTGTTGAGGGATGTC.12 neural_progenitor_cell 1.303548 TTTGTTGCAATATCCG.12 neural_progenitor_cell 0.817161 TTTGTTGCATGCGTGC.12 neuron 0.531878 <p>36557 rows \u00d7 2 columns</p> <pre><code>X_latent = mapper.get_latent_representation(query_adata)\nquery_adata.obsm[\"X_latent\"] = X_latent\nquery_adata.obs[\"best_label\"] = ct_transfer[\"best_label\"]\n\nsc.pp.neighbors(query_adata, use_rep=\"X_latent\", method=\"rapids\")\nsc.tl.umap(query_adata, min_dist=0.3, method=\"rapids\")\nsc.pl.umap(query_adata, color=[\"condition\", \"best_label\"], wspace=0.4)\n</code></pre> <pre>\n<code>Warning: Query dataset is missing 2472 features from the reference dataset. Adding missing features as zero-filled columns.\nWARNING: .obsp[\"connectivities\"] have not been computed using umap\n</code>\n</pre> <p>Looks quite good! Now we can quantify the difference between the FXS dataset and the HNOCA. For this, we first use the wkNN graph to find matched (meta-)cells for each cell in the FXS dataset. Then we perform a differential expression analysis between the matched HNOCA cells and the query using an F-test.</p> <pre><code>matched_adata = mapper.get_matched_expression()\nmatched_adata\n</code></pre> <pre>\n<code>AnnData object with n_obs \u00d7 n_vars = 36557 \u00d7 3000\n    obs: 'sample', 'age', 'sex', 'disease', 'condition', 'publication', 'sc_method', 'batch_in_data', '_scvi_batch', '_scvi_labels', 'snapseed_level_1', 'snapseed_level_2', 'snapseed_level_3', 'snapseed_level_4', 'snapseed_level_5', 'snapseed_level_1_final', 'snapseed_level_2_final', 'snapseed_level_3_final', 'snapseed_level_4_final', 'snapseed_level_5_final', 'conditions_combined', 'annot_level_1', 'annot_level_2', 'annot_level_3', 'annot_level_4', 'annot_region', 'CellClass', 'Subregion', 'SummarizedRegion', 'NeurotransmitterTransporter', 'CellType', 'annot_region_rev', 'SummarizedRegion_hier', 'annot_region_rev2', 'annot_level_1_plus', 'annot_level_2_plus', 'annot_level_3_plus', 'annot_level_4_plus', 'annot_region_plus', 'annot_region_rev_plus', 'annot_region_rev2_plus', 'pearsonr_HNOCA_matched', 'is_control', 'avgdist_HNOCA_matched', 'pearsonr_HNOCA_matched_mtl', 'full_sample', 'nFeatures', 'louvain', 'louvain_1', 'batch', 'snapseed_pca_rss_level_1', 'snapseed_pca_rss_level_12', 'snapseed_pca_rss_level_123'\n    var: 'ensembl', 'gene_symbol', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'gene_length', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n    obsm: 'X_latent'</code>\n</pre> <pre><code>paired_de = stats.test_de_paired(\n    query_adata,\n    matched_adata,\n    num_threads=4,\n    var_names=query_adata.var_names,\n    adjust_method=\"holm\",\n)\npaired_de\n</code></pre> f coef pval padj A2M 1.005743 -0.010660 5.840427e-01 1.000000e+00 ACTA2 1.005277 -0.019927 6.148829e-01 1.000000e+00 ACTC1 1.004356 -0.020906 6.777461e-01 1.000000e+00 ACTN2 1.012864 -0.019045 2.217502e-01 1.000000e+00 ADCYAP1 1.073479 -0.076012 1.221778e-11 4.398402e-09 ... ... ... ... ... ZIC1 1.182211 -0.311655 2.220446e-16 1.172396e-13 ZIC2 1.003396 -0.041030 7.458421e-01 1.000000e+00 ZIC4 1.150357 -0.153911 2.220446e-16 1.172396e-13 ZNF503 1.013888 0.077502 1.873387e-01 1.000000e+00 ZNF843 1.002726 -0.005273 7.946881e-01 1.000000e+00 <p>528 rows \u00d7 4 columns</p> <pre><code>plt.scatter(paired_de[\"coef\"], -np.log10(paired_de[\"pval\"]), s=10)\nplt.ylabel(\"-Log10(P)\")\nplt.show()\n</code></pre>"},{"location":"vignettes/atlas_mapping/#mapping-new-data-to-the-human-neural-organoid-cell-atlas-hnoca","title":"Mapping new data to the Human Neural Organoid Cell Atlas (HNOCA)","text":"<p>We built the HNOCA as a comprehensive collection of (healthy) neural organoid datasets. One can view it as a baseline of how neural organoids can \"look like\" and therefore it can be very valuable to compare new experimental data, e.g. from disease models to the HNOCA. Moreover, we highly encourage  the community to help further expand the atlas over time and submit new datasets to be inclued. </p> <p>Here we'll show how you can map new data to the HNOCA and how to perform quantitative comparisons. Analogous to our analysis in the manuscript, we map scRNA-seq data from a brain organoid model of fragile X syndrome (Kang et al.) and then perform DE analysis. First, let's load all the necessary libraries and the HNOCA data.</p>"},{"location":"vignettes/exploration/","title":"HNOCA exploration and mapping","text":"<pre><code>import os\n\nimport scanpy as sc\n\nos.chdir(\"/home/fleckj/scratch/hnoca/\")\n</code></pre> <pre><code>hnoca_adata = sc.read(\"HNOCA_hv2k.h5ad\")\nprint(hnoca_adata)\n</code></pre> <pre>\n<code>AnnData object with n_obs \u00d7 n_vars = 1770578 \u00d7 2000\n    obs: 'assay_sc', 'assay_differentiation', 'assay_type_differentiation', 'bio_sample', 'cell_line', 'cell_type', 'development_stage', 'disease', 'ethnicity', 'gm', 'id', 'individual', 'organ', 'organism', 'sex', 'state_exact', 'sample_source', 'source_doi', 'suspension_type_original', 'tech_sample', 'treatment', 'assay_sc_original', 'cell_line_original', 'cell_type_original', 'development_stage_original', 'disease_original', 'ethnicity_original', 'organ_original', 'organism_original', 'sex_original', 'suspension_type', 'obs_names_original', 'organoid_age_days', 'publication', 'doi', 'batch', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'total_counts_mt', 'log1p_total_counts_mt', 'pct_counts_mt', 'leiden_pca_unintegrated_1', 'leiden_pca_unintegrated_80', 'leiden_pca_rss_1', 'leiden_pca_rss_80', 'snapseed_pca_unintegrated_level_1', 'snapseed_pca_unintegrated_level_2', 'snapseed_pca_unintegrated_level_3', 'snapseed_pca_unintegrated_level_4', 'snapseed_pca_unintegrated_level_5', 'snapseed_pca_unintegrated_level_12', 'snapseed_pca_unintegrated_level_123', 'snapseed_pca_unintegrated_level_1234', 'snapseed_pca_unintegrated_level_12345', 'snapseed_pca_rss_level_1', 'snapseed_pca_rss_level_2', 'snapseed_pca_rss_level_3', 'snapseed_pca_rss_level_4', 'snapseed_pca_rss_level_5', 'snapseed_pca_rss_level_12', 'snapseed_pca_rss_level_123', 'snapseed_pca_rss_level_1234', 'snapseed_pca_rss_level_12345', 'leiden_scpoli_1', 'leiden_scpoli_80', 'snapseed_scpoli_level_1', 'snapseed_scpoli_level_2', 'snapseed_scpoli_level_3', 'snapseed_scpoli_level_4', 'snapseed_scpoli_level_5', 'snapseed_scpoli_level_12', 'snapseed_scpoli_level_123', 'snapseed_scpoli_level_1234', 'snapseed_scpoli_level_12345', 'annot_region_rev2', 'annot_level_3_rev2', 'annot_level_4_rev2', 'annot_ntt_rev2'\n    var: 'ensembl', 'gene_symbol', 'mt', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'gene_length', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'highly_variable_nbatches'\n    uns: 'annot_region_rev2_colors', 'hvg', 'knn_pca_rss', 'knn_pca_unintegrated', 'knn_scpoli', 'log1p'\n    obsm: 'X_pca_rss', 'X_pca_unintegrated', 'X_rss', 'X_scpoli', 'X_umap_pca_rss', 'X_umap_pca_unintegrated', 'X_umap_scpoli'\n    layers: 'counts', 'counts_lengthnorm', 'lognorm'\n    obsp: 'knn_pca_rss_connectivities', 'knn_pca_rss_distances', 'knn_pca_unintegrated_connectivities', 'knn_pca_unintegrated_distances', 'knn_scpoli_connectivities', 'knn_scpoli_distances'\n</code>\n</pre> <p>The most common and straight forward thing to check on a single-cell dataset is to explore gene expression patterns. For instance, we can plot the expression of some marker genes on a UMAP embedding.</p> <pre><code>hnoca_adata.obsm[\"X_umap\"] = hnoca_adata.obsm[\"X_umap_scpoli\"].copy()\nsc.pl.umap(\n    hnoca_adata,\n    color=[\"FOXG1\", \"EMX1\", \"BCL11B\", \"SATB2\", \"CA8\", \"SLC17A6\"],\n    color_map=\"inferno\",\n    ncols=3,\n)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"vignettes/exploration/#exploring-and-mapping-the-hnoca","title":"Exploring and mapping the HNOCA","text":"<p>The Human Neural Organoid Cell Atlas (HNOCA) is a continuously expanding collection of single-cell RNA-seq data from human neural organoids. Exploring the dataset will give you a sense of the diversity of cell types present in human brain organoids and mapping to a primary reference uncovers what fraction of human neural diversity can be captured in vitro.</p> <p>In this notebook, we will explore the HNOCA dataset, compute glycolysis scores and show you how to perform query-to-reference to an atlas of the developing human brain (Braun at al.). First, let's load some libraries and the data.</p>"},{"location":"vignettes/get_started/","title":"Get started with the Human Neural Organoid Cell Atlas Toolbox","text":"<p>The HNOCA-tools provides a set of tools we used to generate and analyze the Human Neural Organoid Cell Atlas. Among other things, it provides functions to:</p> <ul> <li>Rapidly annotate cell types based on marker genes</li> <li>Map query data to the reference atlas</li> <li>Transfer annotations between datasets</li> <li>Compute 'presence scores' for query data based on the reference atlas</li> <li>Perform differential expression analysis</li> </ul> <p>Here is a quick start guide to the basic functions. More detailed vignettes will be available soon.</p>"},{"location":"vignettes/get_started/#annotation","title":"\ud83d\udd8b\ufe0f Annotation","text":"<p>We developed snapseed to rapidly annotate the HNOCA. It annotates cells based on manually defined sets of marker genes for individual cell types or cell type hierarchies. It is fast (i.e. GPU-accelerated) and simple to enable annotation of very large datasets.</p> <pre><code>import hnoca.snapseed as snap\nfrom hnoca.snapseed.utils import read_yaml\n\n# Read in the marker genes\nmarker_genes = read_yaml(\"marker_genes.yaml\")\n\n# Annotate anndata objects\nsnap.annotate(\n    adata,\n    marker_genes,\n    group_name=\"clusters\",\n    layer=\"lognorm\",\n)\n\n# Or for more complex hierarchies\nsnap.annotate_hierarchy(\n    adata,\n    marker_genes,\n    group_name=\"clusters\",\n    layer=\"lognorm\",\n)\n</code></pre>"},{"location":"vignettes/get_started/#mapping","title":"\ud83d\uddfa\ufe0f Mapping","text":"<p>For reference mapping, we mostly rely on scPoli and scANVI. Based on pretrained models, we here provide a simple interface to map query data to the reference atlas.</p> <pre><code>import scvi\nimport hnoca.mapping as mapping\n\n# Load the reference model\nref_model = scvi.model.SCANVI.load(\n    os.path.join(\"model.pt\"),\n    adata=ref_adata,\n)\n\n# Map query data\nmapper = mapping.AtlasMapper(ref_model)\nmapper.map_query(query_adata, retrain=\"partial\", max_epochs=100, batch_size=1024)\n</code></pre> <p>Now that the query dataset is mapped, we can perform kNN-based label transfer and presence score calculation.</p> <pre><code># Compute the weighted kNN\nmapper.compute_wknn(k=100)\n\n# Transfer labels\ncelltype_transfer = mapper.transfer_labels(label_key=\"cell_type\")\npresence_scores = mapper.get_presence_scores(split_by=\"batch\")\n</code></pre>"},{"location":"vignettes/get_started/#differential-expression","title":"\ud83d\udcca Differential expression","text":"<p>We have used ANOVA for DE analysis between the HNOCA and the reference atlas. Here, this is implemented as the <code>test_de()</code> function.</p> <pre><code>import hnoca.stats as stats\n\n# Perform DE analysis\nde_df = stats.test_de(\n    joint_adata,\n    group_key=\"origin\",\n    return_coef_group=\"organoid\",\n    adjust_method=\"holm\",\n)\n</code></pre> <p>In addition to DE testing on the atlas itself, we found it useful to treat the atlas as a universal \"control\" and test for DE w.r.t query datasets. For this, we first compute the matched expression profile for each cell in the query dataset and then test for DE using an F-test.</p> <pre><code># Compute matched expression profiles based on mapped data\nmatched_adata = mapper.get_matched_expression()\n\n# Perform DE analysis\nde_df = stats.test_de_paired(\n    query_adata,\n    matched_adata,\n    adjust_method=\"holm\",\n)\n</code></pre>"},{"location":"vignettes/reference_mapping/","title":"Primary reference mapping","text":"<pre><code>import os\n\nimport scanpy as sc\nimport scvi\n\nimport hnoca.map as hmap\n\nos.chdir(\"/home/fleckj/scratch/hnoca/\")\n</code></pre> <pre><code># Read reference and query data\nref_adata = sc.read(\"BraunLinnarsson_2023_devbrain_hv2k.h5ad\")\nquery_adata = sc.read(\"AminPasca_2023_organoid_screen_hv2k.h5ad\")\n\n# Format batch columns\nquery_adata.obs[\"batch\"] = query_adata.obs[\"orig.ident\"].astype(str).copy()\nref_adata.obs[\"batch\"] = ref_adata.obs[\"Donor\"].astype(str).copy()\n\n# Load reference model\nref_model = scvi.model.SCANVI.load(\n    \"scarches_BraunLinnarsson/model.pt\",\n    adata=ref_adata,\n)\nprint(ref_model)\n</code></pre> <p>Now we can use the <code>AtlasMapper</code> from HNOCA-tools to map the organoid data to the reference atlas. Under the hood this is using the transfer learning functionality of scANVI to finetune te model to the query dataset. We finetune for 100 epochs (<code>max_epochs</code>) with a batch size of 1024 (<code>batch_size</code>) and use <code>retrain=\"partial\"</code> to only retrain the weights corresponding to the new batch covariates. </p> <pre><code># Initiate mapper\nmapper = hmap.AtlasMapper(ref_model)\n# Map query data to reference\nmapper.map_query(query_adata, retrain=\"partial\", max_epochs=100, batch_size=1024)\n</code></pre> <p>We then compute a weighted kNN graph between the query and reference data.</p> <pre><code>mapper.compute_wknn(k=100)\n</code></pre> <p>Based on this wkNN mapping, we can now transfer labels from the reference and to estimate cell type composition of the query. We can also compute presence scores with respect to the reference data to assess which reference cell types are covered in the screen.</p> <pre><code>subregion_transfer = mapper.transfer_labels(label_key=\"CellClass\")\nsubregion_transfer[[\"best_label\", \"best_score\"]]\n</code></pre> best_label best_score 44_33_8__s1 Radial glia 1.789107 44_79_20__s1 Radial glia 0.617641 44_23_10__s1 Radial glia 1.113593 15_50_8__s1 Neurolast 0.360920 15_86_61__s1 Neurolast 0.315698 ... ... ... 6_94_77__s8 Neuron 0.563865 35_39_65__s8 Oligo 16.431843 30_36_44__s8 Neuron 0.666777 30_56_8__s8 Neuron 0.315283 23_5_66__s8 Radial glia 1.151799 <p>36265 rows \u00d7 2 columns</p> <p>Let's check how this looks on a UMAP. We can see that this matches the original author annotations (<code>\"class\"</code>) quite well.</p> <pre><code>query_adata.obs[\"best_label\"] = subregion_transfer[\"best_label\"]\nquery_adata.obs[\"best_score\"] = subregion_transfer[\"best_score\"]\nsc.pl.umap(query_adata, color=[\"class\", \"best_label\", \"best_score\"], ncols=1)\n</code></pre> <p>Next, we'd like to know which cell types of the reference atlas are covered by the organoid screen. For this, we can compute the per-condition presence scores based on the wkNN graph. (Depending on the number of conditions this can take a while, even if you are running it on a GPU.)</p> <pre><code>presence_scores = mapper.get_presence_scores(split_by=\"condition\")\n</code></pre> <pre>\n<code>GPU detected and cuml installed. Use cuML for neighborhood estimation.\n</code>\n</pre> <p>Now let's check out the presence scores on a umap of the reference atlas.</p> <pre><code>ref_adata.obs[\"max_presence_scores\"] = presence_scores[\"max\"]\nsc.pl.umap(ref_adata, color=[\"CellClass\", \"Subregion\", \"max_presence_scores\"], ncols=1, cmap=\"Blues\")\n</code></pre> <p>From here on one can perform various other analysis based on the presence scores, e.g. compare them with the organoid atlas to reveal cell types for which coverage was improved by the screen. </p>"},{"location":"vignettes/reference_mapping/#reference-mapping-with-hnoca-tools","title":"Reference mapping with HNOCA-tools","text":"<p>In this tutorial we'll explore how to perform reference mapping using the HNOCA toolbox. Analogous to our analysis in the HNOCA manuscript, we map an organoid morphogen screen dataset (Amin at al.) to a reference atlas of the developing human brain (Braun at al.). We already trained a scANVI model for this. Based on this model HNOCA-tools provides functions to map the organoid data to the reference atlas and make quantitative comparisons.</p> <p>To get started, we first load all necessary pacakges and load the data &amp; model.</p>"}]}